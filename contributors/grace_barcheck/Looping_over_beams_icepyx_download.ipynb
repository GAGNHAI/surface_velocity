{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Query icepyx; see what tracks are available in area of interest\n",
    "\n",
    "2. Save track numbers, beams, and repeat numbers into a dictionary\n",
    "\n",
    "3. For each track/beam combination, loop over all possible repeat pairs\n",
    "\n",
    "    A. Load all beams and all repeats for that track using icepyx (?). For all beams / repeats:\n",
    "    \n",
    "        - Do whatever we are doing with ATL03\n",
    "    \n",
    "        - Fill in nan gaps with noise\n",
    "        \n",
    "    B. For each repeat pair:\n",
    "        \n",
    "        - Loop across the along track coordinates: \n",
    "        \n",
    "            Choices: window size, search width, running average window size, step, where to save data geographically\n",
    "            \n",
    "            Output: Best lag, corresponding correlation coefficient, equivalent along-track velocity\n",
    "            \n",
    "        - Save results in a text file with date collected, dx from ATL03 processing, lat, lon, veloc, correlation coefficient, best lag, # contributing nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'query' from 'icepyx' (/srv/conda/envs/notebook/lib/python3.7/site-packages/icepyx/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e4329610c6ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorrelate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0micepyx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mipqr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'query' from 'icepyx' (/srv/conda/envs/notebook/lib/python3.7/site-packages/icepyx/__init__.py)"
     ]
    }
   ],
   "source": [
    "from icepyx import icesat2data as ipd\n",
    "import os, glob, re, h5py, sys, pyproj, shutil\n",
    "import matplotlib as plt\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from astropy.time import Time\n",
    "from scipy.signal import correlate\n",
    "# from icepyx import query as ipqr\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foundation Ice Stream\n",
    "short_name = 'ATL06'\n",
    "spatial_extent = [-65, -86, -55, -81]\n",
    "date_range = ['2019-01-01','2019-06-31'] # i can't remember when the data starts\n",
    "date_range = ['2018-03-01','2020-05-31']\n",
    "\n",
    "# # Pine Island Glacier\n",
    "# short_name = 'ATL06'\n",
    "# spatial_extent = [-102, -76, -98, -74.5]\n",
    "# date_range = ['2019-06-18','2019-06-25']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_a = ipd.Icesat2Data(short_name, spatial_extent, date_range, version='003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL06\n",
      "['2018-03-01', '2020-05-31']\n",
      "00:00:00\n",
      "23:59:59\n",
      "003\n",
      "['bounding box', [-65, -86, -55, -81]]\n"
     ]
    }
   ],
   "source": [
    "print(region_a.dataset)\n",
    "print(region_a.dates)\n",
    "print(region_a.start_time)\n",
    "print(region_a.end_time)\n",
    "print(region_a.dataset_version)\n",
    "print(region_a.spatial_extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_a.visualize_spatial_extent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003\n",
      "{'feed': {'entry': [{'archive_center': 'NASA NSIDC DAAC',\n",
      "                     'associations': {'services': ['S1568899363-NSIDC_ECS',\n",
      "                                                   'S1613669681-NSIDC_ECS',\n",
      "                                                   'S1613689509-NSIDC_ECS']},\n",
      "                     'boxes': ['-90 -180 90 180'],\n",
      "                     'browse_flag': False,\n",
      "                     'coordinate_system': 'CARTESIAN',\n",
      "                     'data_center': 'NSIDC_ECS',\n",
      "                     'dataset_id': 'ATLAS/ICESat-2 L3A Land Ice Height V002',\n",
      "                     'has_formats': True,\n",
      "                     'has_spatial_subsetting': True,\n",
      "                     'has_temporal_subsetting': True,\n",
      "                     'has_transforms': False,\n",
      "                     'has_variables': True,\n",
      "                     'id': 'C1631076765-NSIDC_ECS',\n",
      "                     'links': [{'href': 'https://n5eil01u.ecs.nsidc.org/ATLAS/ATL06.002/',\n",
      "                                'hreflang': 'en-US',\n",
      "                                'length': '0.0KB',\n",
      "                                'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n",
      "                               {'href': 'https://search.earthdata.nasa.gov/search/granules?p=C1631076765-NSIDC_ECS&q=atl06%20v002&m=-113.62703547966265!-24.431396484375!0!1!0!0%2C2&tl=1556125020!4',\n",
      "                                'hreflang': 'en-US',\n",
      "                                'length': '0.0KB',\n",
      "                                'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n",
      "                               {'href': 'https://openaltimetry.org/',\n",
      "                                'hreflang': 'en-US',\n",
      "                                'length': '0.0KB',\n",
      "                                'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n",
      "                               {'href': 'https://doi.org/10.5067/ATLAS/ATL06.002',\n",
      "                                'hreflang': 'en-US',\n",
      "                                'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#'},\n",
      "                               {'href': 'https://doi.org/10.5067/ATLAS/ATL06.002',\n",
      "                                'hreflang': 'en-US',\n",
      "                                'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'}],\n",
      "                     'online_access_flag': True,\n",
      "                     'orbit_parameters': {'inclination_angle': '92.0',\n",
      "                                          'number_of_orbits': '0.071428571',\n",
      "                                          'period': '94.29',\n",
      "                                          'start_circular_latitude': '0.0',\n",
      "                                          'swath_width': '36.0'},\n",
      "                     'organizations': ['NASA NSIDC DAAC',\n",
      "                                       'NASA/GSFC/EOS/ESDIS'],\n",
      "                     'original_format': 'ISO19115',\n",
      "                     'processing_level_id': 'Level 3',\n",
      "                     'short_name': 'ATL06',\n",
      "                     'summary': 'This data set (ATL06) provides geolocated, '\n",
      "                                'land-ice surface heights (above the WGS 84 '\n",
      "                                'ellipsoid, ITRF2014 reference frame), plus '\n",
      "                                'ancillary parameters that can be used to '\n",
      "                                'interpret and assess the quality of the '\n",
      "                                'height estimates. The data were acquired by '\n",
      "                                'the Advanced Topographic Laser Altimeter '\n",
      "                                'System (ATLAS) instrument on board the Ice, '\n",
      "                                'Cloud and land Elevation Satellite-2 '\n",
      "                                '(ICESat-2) observatory.',\n",
      "                     'time_start': '2018-10-14T00:00:00.000Z',\n",
      "                     'title': 'ATLAS/ICESat-2 L3A Land Ice Height V002',\n",
      "                     'version_id': '002'},\n",
      "                    {'archive_center': 'NASA NSIDC DAAC',\n",
      "                     'associations': {'services': ['S1568899363-NSIDC_ECS',\n",
      "                                                   'S1613669681-NSIDC_ECS',\n",
      "                                                   'S1613689509-NSIDC_ECS']},\n",
      "                     'boxes': ['-90 -180 90 180'],\n",
      "                     'browse_flag': False,\n",
      "                     'coordinate_system': 'CARTESIAN',\n",
      "                     'data_center': 'NSIDC_ECS',\n",
      "                     'dataset_id': 'ATLAS/ICESat-2 L3A Land Ice Height V003',\n",
      "                     'has_formats': True,\n",
      "                     'has_spatial_subsetting': True,\n",
      "                     'has_temporal_subsetting': True,\n",
      "                     'has_transforms': False,\n",
      "                     'has_variables': True,\n",
      "                     'id': 'C1706333750-NSIDC_ECS',\n",
      "                     'links': [{'href': 'https://n5eil01u.ecs.nsidc.org/ATLAS/ATL06.003/',\n",
      "                                'hreflang': 'en-US',\n",
      "                                'length': '0.0KB',\n",
      "                                'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n",
      "                               {'href': 'https://search.earthdata.nasa.gov/search/granules?p=C1706333750-NSIDC_ECS&q=atl06%20v003&m=-29.109278436791882!-59.86889648437499!1!1!0!0%2C2&tl=1572814258!4!!',\n",
      "                                'hreflang': 'en-US',\n",
      "                                'length': '0.0KB',\n",
      "                                'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n",
      "                               {'href': 'https://openaltimetry.org/',\n",
      "                                'hreflang': 'en-US',\n",
      "                                'length': '0.0KB',\n",
      "                                'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n",
      "                               {'href': 'https://doi.org/10.5067/ATLAS/ATL06.003',\n",
      "                                'hreflang': 'en-US',\n",
      "                                'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#'},\n",
      "                               {'href': 'https://doi.org/10.5067/ATLAS/ATL06.003',\n",
      "                                'hreflang': 'en-US',\n",
      "                                'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'}],\n",
      "                     'online_access_flag': True,\n",
      "                     'orbit_parameters': {'inclination_angle': '92.0',\n",
      "                                          'number_of_orbits': '0.071428571',\n",
      "                                          'period': '94.29',\n",
      "                                          'start_circular_latitude': '0.0',\n",
      "                                          'swath_width': '36.0'},\n",
      "                     'organizations': ['NASA NSIDC DAAC',\n",
      "                                       'NASA/GSFC/EOS/ESDIS'],\n",
      "                     'original_format': 'ISO19115',\n",
      "                     'processing_level_id': 'Level 3',\n",
      "                     'short_name': 'ATL06',\n",
      "                     'summary': 'This data set (ATL06) provides geolocated, '\n",
      "                                'land-ice surface heights (above the WGS 84 '\n",
      "                                'ellipsoid, ITRF2014 reference frame), plus '\n",
      "                                'ancillary parameters that can be used to '\n",
      "                                'interpret and assess the quality of the '\n",
      "                                'height estimates. The data were acquired by '\n",
      "                                'the Advanced Topographic Laser Altimeter '\n",
      "                                'System (ATLAS) instrument on board the Ice, '\n",
      "                                'Cloud and land Elevation Satellite-2 '\n",
      "                                '(ICESat-2) observatory.',\n",
      "                     'time_start': '2018-10-14T00:00:00.000Z',\n",
      "                     'title': 'ATLAS/ICESat-2 L3A Land Ice Height V003',\n",
      "                     'version_id': '003'}],\n",
      "          'id': 'https://cmr.earthdata.nasa.gov:443/search/collections.json?short_name=ATL06',\n",
      "          'title': 'ECHO dataset metadata',\n",
      "          'updated': '2020-07-22T17:54:41.186Z'}}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(region_a.latest_version())\n",
    "print(region_a.dataset_all_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-9a4d45aeb37b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#get a list of the available granule IDs that meet your search criteria\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mregion_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavail_granules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/icepyx/core/icesat2data.py\u001b[0m in \u001b[0;36mavail_granules\u001b[0;34m(self, ids)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgranules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgranules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_avail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMRparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreqparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/icepyx/core/granules.py\u001b[0m in \u001b[0;36mget_avail\u001b[0;34m(self, CMRparams, reqparams)\u001b[0m\n\u001b[1;32m    110\u001b[0m             response = requests.get(granule_search_url, headers=headers,\\\n\u001b[1;32m    111\u001b[0m                                     params=apifmt.combine_params(CMRparams,\\\n\u001b[0;32m--> 112\u001b[0;31m                                                                {k: reqparams[k] for k in ('page_size','page_num')}))\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    424\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unexpected EOF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#build and view the parameters that will be submitted in our query\n",
    "region_a.CMRparams\n",
    "\n",
    "#get a list of the available granule IDs that meet your search criteria TAKES A LONG TIME\n",
    "region_a.avail_granules(ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print detailed information about the returned search results\n",
    "region_a.granules.avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/home/jovyan/shared/surface_velocity/FIS_ATL06'\n",
    "ATL06_files=glob.glob(os.path.join(datapath, '*.h5'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0080', '1131', '0232', '1031', '0634', '0507', '0131', '0192', '0354', '1061', '0492', '0690', '0970', '0187', '0558', '1335', '0741', '0659', '0894', '1183', '0680', '1101', '1168', '0034', '0568', '0705', '0293', '0711', '1040', '0070', '0543', '1244', '1192', '0314', '0126', '1193', '1147', '0253', '0451', '1122', '0994', '0391', '0141', '0979', '0476', '1223', '1137', '0726', '0918', '1314', '1253', '1177', '0750', '0330', '1010', '0193', '0781', '0872', '1299', '0629', '1055', '0695', '0309', '0467', '0802', '0644', '0461', '0415', '0635', '0924', '0482', '1214', '1076', '0573', '0339', '0833', '0171', '0446', '0385', '1336', '0796', '0369', '0756', '1238', '0674', '0903', '0955', '0650', '0772', '0832', '0766', '0513', '0308', '0857', '0720', '1162', '0848', '0202', '0019', '0071', '1138', '1259', '0522', '0390', '1254', '0360', '0933', '1025', '0512', '1000', '1153', '0842', '0400', '1351', '0751', '0628', '0537', '0583', '0878', '1320', '0491', '0552', '0421', '1315', '1015', '0954', '0040', '1275', '0132', '0812', '0598', '0985', '1016', '1330', '0324', '0589', '1132', '0909', '0049', '0370', '0263', '0735', '0613', '0095', '0431', '0345', '1071', '0689', '1274', '1376', '1345', '0811', '0004', '0888', '0452', '0065', '0964', '0217', '1208', '0893', '0147', '1360', '0939', '1092', '1229', '0110', '1375', '0406', '0817', '0436', '0863', '0787', '0934', '0574', '0949', '0873', '1070', '0497', '0009', '1366', '0528', '1198', '0025', '0619', '0247', '0010', '1107', '1046', '0162', '1305', '1116', '0604', '0827', '0665', '0430', '0116', '0771', '0208', '0086', '0375', '0186', '0248', '0299', '1381', '0284', '0269', '1086', '1290', '0223', '1284', '0177', '0101', '1077', '0156', '0278', '1269', '0238', '0055'])\n",
      "['04', '02', '03', '01']\n"
     ]
    }
   ],
   "source": [
    "rgts = {}\n",
    "for filepath in ATL06_files:\n",
    "    filename = filepath.split('/')[-1]\n",
    "    rgt = filename.split('_')[3][0:4]\n",
    "    track = filename.split('_')[3][4:6]\n",
    "#     print(rgt,track)\n",
    "    if not rgt in rgts.keys():\n",
    "        rgts[rgt] = []\n",
    "        rgts[rgt].append(track)\n",
    "    else:\n",
    "        rgts[rgt].append(track)\n",
    "\n",
    "\n",
    "# all rgt values in our study are are in rgts.keys()\n",
    "print(rgts.keys())\n",
    "\n",
    "# available tracks for each rgt are in rgts[rgt]; ex.:\n",
    "print(rgts['0848'])\n",
    "\n",
    "# let's work 0848, our first good track friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atl06_to_dict(filename, beam, field_dict=None, index=None, epsg=None):\n",
    "    \"\"\"\n",
    "        Read selected datasets from an ATL06 file\n",
    "\n",
    "        Input arguments:\n",
    "            filename: ATl06 file to read\n",
    "            beam: a string specifying which beam is to be read (ex: gt1l, gt1r, gt2l, etc)\n",
    "            field_dict: A dictinary describing the fields to be read\n",
    "                    keys give the group names to be read, \n",
    "                    entries are lists of datasets within the groups\n",
    "            index: which entries in each field to read\n",
    "            epsg: an EPSG code specifying a projection (see www.epsg.org).  Good choices are:\n",
    "                for Greenland, 3413 (polar stereographic projection, with Greenland along the Y axis)\n",
    "                for Antarctica, 3031 (polar stereographic projection, centered on the Pouth Pole)\n",
    "        Output argument:\n",
    "            D6: dictionary containing ATL06 data.  Each dataset in \n",
    "                dataset_dict has its own entry in D6.  Each dataset \n",
    "                in D6 contains a numpy array containing the \n",
    "                data\n",
    "    \"\"\"\n",
    "    if field_dict is None:\n",
    "        field_dict={None:['latitude','longitude','h_li', 'atl06_quality_summary'],\\\n",
    "                    'ground_track':['x_atc','y_atc'],\\\n",
    "                    'fit_statistics':['dh_fit_dx', 'dh_fit_dy']}\n",
    "    D={}\n",
    "    # below: file_re = regular expression, it will pull apart the regular expression to get the information from the filename\n",
    "    file_re=re.compile('ATL06_(?P<date>\\d+)_(?P<rgt>\\d\\d\\d\\d)(?P<cycle>\\d\\d)(?P<region>\\d\\d)_(?P<release>\\d\\d\\d)_(?P<version>\\d\\d).h5')\n",
    "    with h5py.File(filename,'r') as h5f:\n",
    "        for key in field_dict:\n",
    "            for ds in field_dict[key]:\n",
    "                if key is not None:\n",
    "                    ds_name=beam+'/land_ice_segments/'+key+'/'+ds\n",
    "                else:\n",
    "                    ds_name=beam+'/land_ice_segments/'+ds\n",
    "                if index is not None:\n",
    "                    D[ds]=np.array(h5f[ds_name][index])\n",
    "                else:\n",
    "                    D[ds]=np.array(h5f[ds_name])\n",
    "                if '_FillValue' in h5f[ds_name].attrs:\n",
    "                    bad_vals=D[ds]==h5f[ds_name].attrs['_FillValue']\n",
    "                    D[ds]=D[ds].astype(float)\n",
    "                    D[ds][bad_vals]=np.NaN\n",
    "        D['data_start_utc'] = h5f['/ancillary_data/data_start_utc'][:]\n",
    "        D['delta_time'] = h5f['/' + beam + '/land_ice_segments/delta_time'][:]\n",
    "        D['segment_id'] = h5f['/' + beam + '/land_ice_segments/segment_id'][:]\n",
    "    if epsg is not None:\n",
    "        xy=np.array(pyproj.proj.Proj(epsg)(D['longitude'], D['latitude']))\n",
    "        D['x']=xy[0,:].reshape(D['latitude'].shape)\n",
    "        D['y']=xy[1,:].reshape(D['latitude'].shape)\n",
    "    temp=file_re.search(filename)\n",
    "    D['rgt']=int(temp['rgt'])\n",
    "    D['cycle']=int(temp['cycle'])\n",
    "    D['beam']=beam\n",
    "    return D\n",
    "\n",
    "# A revised code to plot the elevations of segment midpoints (h_li):\n",
    "def plot_elevation(D6, ind=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot midpoint elevation for each ATL06 segment\n",
    "    \"\"\"\n",
    "    if ind is None:\n",
    "        ind=np.ones_like(D6['h_li'], dtype=bool)\n",
    "    # pull out heights of segment midpoints\n",
    "    h_li = D6['h_li'][ind]\n",
    "    # pull out along track x coordinates of segment midpoints\n",
    "    x_atc = D6['x_atc'][ind]\n",
    "\n",
    "    plt.plot(x_atc, h_li, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over rgts and do the correlation processing\n",
    "\n",
    "TOMORROW: START WITH NEXT CELL IN OLD CODE, IMPLEMENT MAKING THE X1 VEC AND LOOPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190523195046_08480311_003_01.h5']\n",
      "For cycle 03, read 1 data files of which 0 gave errors\n",
      "['/home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190822153035_08480411_003_01.h5']\n",
      "For cycle 04, read 1 data files of which 0 gave errors\n",
      "[]\n",
      "For cycle 05, read 0 data files of which 0 gave errors\n",
      "[]\n",
      "For cycle 06, read 0 data files of which 0 gave errors\n",
      "[]\n",
      "For cycle 07, read 0 data files of which 0 gave errors\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'correlate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1c7aa36ab5fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;31m# correlate old with newer data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrelate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_li1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_li2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'direct'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;31m# normalize correlation function; simplest way (not quite correct)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'correlate' is not defined"
     ]
    }
   ],
   "source": [
    "cycles = ['03','04','05','06','07'] # not doing 1 and 2, because don't overlap exactly\n",
    "# this could be future work\n",
    "\n",
    "beams = ['gt1l','gt1r','gt2l','gt2r','gt3l','gt3r']\n",
    "\n",
    "# try and smooth without filling nans\n",
    "dx = 20 # x_atc coordinate distance\n",
    "smoothing_window_size = int(np.round(40 / dx)) # meters / dx;\n",
    "# ex., 60 m smoothing window is a 3 point running average smoothed dataset, because each point is 20 m apart\n",
    "filt = np.ones(smoothing_window_size)\n",
    "smoothed = True\n",
    "\n",
    "segment_length = 2000 # m\n",
    "search_width = 800 # m\n",
    "\n",
    "\n",
    "for rgt in rgts.keys():\n",
    "    if rgt == '0848': # just want to work on this track for now\n",
    "        \n",
    "        ### load all files for this rgt\n",
    "        rgt_files = glob.glob(os.path.join(datapath, f'*ATL06_*_{rgt}*_003*.h5'))\n",
    "        \n",
    "        ### extract data from all available cycles\n",
    "        x_atc = {}\n",
    "        h_li_raw = {}\n",
    "        h_li = {}\n",
    "        h_li_diff = {}\n",
    "        times = {}\n",
    "        min_seg_ids = {}\n",
    "        min_x_atc = {}\n",
    "\n",
    "        cycles_this_rgt = []\n",
    "        for cycle in cycles:\n",
    "            # load data that matches cycle; put into dictionaries to use shortly\n",
    "            Di = {}\n",
    "            x_atc[cycle] = {}\n",
    "            h_li_raw[cycle] = {}\n",
    "            h_li[cycle] = {}\n",
    "            h_li_diff[cycle] = {}\n",
    "            times[cycle] = {}\n",
    "            min_seg_ids[cycle] = {}\n",
    "            min_x_atc[cycle] = {}\n",
    "\n",
    "\n",
    "\n",
    "            filenames = glob.glob(os.path.join(datapath, f'*ATL06_*_{rgt}{cycle}*_003*.h5'))\n",
    "            print(filenames)\n",
    "            error_count=0\n",
    "            for filename in filenames:\n",
    "                try:\n",
    "                    for beam in beams:\n",
    "                        Di[filename]=atl06_to_dict(filename,'/'+ beam, index=None, epsg=3031)\n",
    "\n",
    "                        times[cycle][beam] = Di[filename]['data_start_utc']\n",
    "\n",
    "                        # extract h_li and x_atc for that section                \n",
    "                        x_atc_tmp = Di[filename]['x_atc']\n",
    "                        h_li_tmp = Di[filename]['h_li']#[ixs]\n",
    "\n",
    "                        # segment ids:\n",
    "                        seg_ids = Di[filename]['segment_id']\n",
    "                        min_seg_ids[cycle][beam] = seg_ids[0]\n",
    "                        #print(len(seg_ids), len(x_atc_tmp))\n",
    "\n",
    "                        # make a monotonically increasing x vector\n",
    "                        # assumes dx = 20 exactly, so be carefull referencing back\n",
    "                        ind = seg_ids - np.nanmin(seg_ids) # indices starting at zero, using the segment_id field, so any skipped segment will be kept in correct location\n",
    "                        x_full = np.arange(np.max(ind)+1) * 20 + x_atc_tmp[0]\n",
    "                        h_full = np.zeros(np.max(ind)+1) + np.NaN\n",
    "                        h_full[ind] = h_li_tmp\n",
    "                        min_x_atc[cycle][beam] = x_atc_tmp[0]\n",
    "\n",
    "\n",
    "                        x_atc[cycle][beam] = x_full\n",
    "                        h_li_raw[cycle][beam] = h_full\n",
    "\n",
    "                        # running average smoother /filter\n",
    "                        if smoothed == True:\n",
    "                            h_smoothed = (1/smoothing_window_size) * np.convolve(filt, h_full, mode = 'same')\n",
    "                            h_li[cycle][beam] = h_smoothed\n",
    "\n",
    "                            # differentiate that section of data\n",
    "                            h_diff = (h_smoothed[1:] - h_smoothed[0:-1]) / (x_full[1:] - x_full[0:-1])\n",
    "                        else: \n",
    "                            h_li[cycle][beam] = h_full\n",
    "                            h_diff = (h_full[1:] - h_full[0:-1]) / (x_full[1:] - x_full[0:-1])\n",
    "\n",
    "                        h_li_diff[cycle][beam] = h_diff\n",
    "\n",
    "#                         # plot\n",
    "#                         axs[0].plot(x_full, h_full)\n",
    "#                         axs[1].plot(x_full[1:], h_diff)\n",
    "#         #                 axs[2].plot(x_atc_tmp[1:] - x_atc_tmp[:-1])\n",
    "#                         axs[2].plot(np.isnan(h_full))\n",
    "#                         axs[3].plot(seg_ids[1:]- seg_ids[:-1])\n",
    "\n",
    "\n",
    "                    cycles_this_rgt+=[cycle]\n",
    "\n",
    "\n",
    "                except KeyError as e:\n",
    "                    print(f'file {filename} encountered error {e}')\n",
    "                    error_count += 1\n",
    "            \n",
    "            print(f\"For cycle {cycle}, read {len(Di)} data files of which {error_count} gave errors\")\n",
    "            \n",
    "        ### Determine # of possible velocities:\n",
    "        n_possible_veloc = len(cycles_this_rgt) -1 # naive, for now; can improve later\n",
    "        for veloc_number in range(n_possible_veloc):\n",
    "            cycle1 = cycles[veloc_number]\n",
    "            cycle2 = cycles[veloc_number+1]\n",
    "            t1_string = times[cycle1]['gt1l'][0].astype(str) #figure out later if just picking hte first one it ok\n",
    "            t1 = Time(t1_string)\n",
    "\n",
    "            t2_string = times[cycle2]['gt1l'][0].astype(str) #figure out later if just picking hte first one it ok\n",
    "            t2 = Time(t2_string)\n",
    "\n",
    "            dt = (t2 - t1).jd # difference in julian days\n",
    "        \n",
    "            velocities = {}     \n",
    "            for beam in beams:\n",
    "                # fig1, axs = plt.subplots(4,1)\n",
    "\n",
    "                ### determine x1: larger value for both beams, if different\n",
    "                x1 = np.nanmax([x_atc[cycle1][beam][0], x_atc[cycle2][beam][0]])                \n",
    "                \n",
    "                # cut out small chunk of data at time t1 (first cycle)\n",
    "                x_full_t1 = x_atc[cycle1][beam]\n",
    "                ix_x1 = np.arange(len(x_full_t1))[x_full_t1 >= x1][0]\n",
    "                ix_x2 = ix_x1 + int(np.round(segment_length/dx))      \n",
    "                x_t1 = x_full_t1[ix_x1:ix_x2]\n",
    "                h_li1 = h_li_diff[cycle1][beam][ix_x1-1:ix_x2-1] # start 1 index earlier because the data are differentiated\n",
    "\n",
    "                # cut out a wider chunk of data at time t2 (second cycle)\n",
    "                x_full_t2 = x_atc[cycle2][beam]\n",
    "                ix_x3 = ix_x1 - int(np.round(search_width/dx)) # offset on earlier end by # indices in search_width\n",
    "                ix_x4 = ix_x2 + int(np.round(search_width/dx)) # offset on later end by # indices in search_width\n",
    "                x_t2 = x_full_t2[ix_x3:ix_x4]\n",
    "                h_li2 = h_li_diff[cycle2][beam][ix_x3:ix_x4]\n",
    "\n",
    "                # plot data\n",
    "                # axs[0].plot(x_t2, h_li2, 'r')\n",
    "                # axs[0].plot(x_t1, h_li1, 'k')\n",
    "                # axs[0].set_xlabel('x_atc (m)')\n",
    "\n",
    "                # correlate old with newer data\n",
    "                corr = correlate(h_li1, h_li2, mode = 'valid', method = 'direct') \n",
    "\n",
    "                # normalize correlation function; simplest way (not quite correct)\n",
    "                # norm_val = np.sqrt(np.sum(h_li1**2)*np.sum(h_li2**2)) # normalize so values range between 0 and 1\n",
    "                # corr = corr / norm_val\n",
    "\n",
    "                # a better way to normalize correlation function: shifting along longer vector\n",
    "                coeff_a_val = np.sum(h_li1**2)\n",
    "                coeff_b_val = np.zeros(len(h_li2) - len(h_li1)+1)\n",
    "                for shift in range(len(h_li2) - len(h_li1)+1):\n",
    "                    coeff_b_val[shift] = np.sum(h_li2[shift:shift + len(h_li1)]**2)\n",
    "                norm_vec = np.sqrt(coeff_a_val * coeff_b_val)\n",
    "                corr = corr / norm_vec\n",
    "\n",
    "\n",
    "        #         lagvec = np.arange( -(len(h_li1) - 1), len(h_li2), 1)# for mode = 'full'\n",
    "        #         lagvec = np.arange( -int(search_width/dx) - 1, int(search_width/dx) +1, 1) # for mode = 'valid'\n",
    "                lagvec = np.arange(- int(np.round(search_width/dx)), int(search_width/dx) +1,1)# for mode = 'valid'\n",
    "\n",
    "                shift_vec = lagvec * dx\n",
    "\n",
    "                ix_peak = np.arange(len(corr))[corr == np.nanmax(corr)][0]\n",
    "                best_lag = lagvec[ix_peak]\n",
    "                best_shift = shift_vec[ix_peak]\n",
    "                velocities[beam] = best_shift/(dt/365)\n",
    "\n",
    "                # axs[1].plot(lagvec,corr)\n",
    "                # axs[1].plot(lagvec[ix_peak],corr[ix_peak], 'r*')\n",
    "                # axs[1].set_xlabel('lag (samples)')\n",
    "\n",
    "                # axs[2].plot(shift_vec,corr)\n",
    "                # axs[2].plot(shift_vec[ix_peak],corr[ix_peak], 'r*')\n",
    "                # axs[2].set_xlabel('shift (m)')\n",
    "\n",
    "                ## plot shifted data\n",
    "                # axs[3].plot(x_t2, h_li2, 'r')\n",
    "                # axs[3].plot(x_t1 - best_shift, h_li1, 'k')\n",
    "                # axs[3].set_xlabel('x_atc (m)')\n",
    "\n",
    "                # axs[0].text(x_t2[100], 0.6*np.nanmax(h_li2), beam)\n",
    "                # axs[1].text(lagvec[5], 0.6*np.nanmax(corr), 'best lag: ' + str(best_lag) + '; corr val: ' + str(np.round(corr[ix_peak],3)))\n",
    "                # axs[2].text(shift_vec[5], 0.6*np.nanmax(corr), 'best shift: ' + str(best_shift) + ' m'+ '; corr val: ' + str(np.round(corr[ix_peak],3)))\n",
    "                # axs[2].text(shift_vec[5], 0.3*np.nanmax(corr), 'veloc of ' + str(np.round(best_shift/(dt/365),1)) + ' m/yr')\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "#         Di={}\n",
    "#         error_count=0\n",
    "#         for file in rgt_files:\n",
    "#             try:\n",
    "#                 D_dict[file]=atl06_to_dict(file, '/gt2l', index=slice(0, -1, 25), epsg=3031)\n",
    "#             except KeyError as e:\n",
    "#                 print(f'file {file} encountered error {e}')\n",
    "#                 error_count += 1\n",
    "#         print(f\"read {len(D_dict)} data files of which {error_count} gave errors\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycles_this_rgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x_atc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
