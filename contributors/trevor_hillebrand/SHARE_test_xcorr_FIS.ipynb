{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test scipy.signal.correlate on some atl06 data from foundation ice stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy, sys, os, pyproj, glob, re, h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import correlate\n",
    "from astropy.time import Time\n",
    "\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test scipy.signal.correlate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33efe5a280ae44ae9a3c9cffd43bf1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'index')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx = 0.1\n",
    "x = np.arange(0,10,dx)\n",
    "y = np.zeros(np.shape(x))\n",
    "ix0 = 30\n",
    "ix1 = 30 + 15\n",
    "y[ix0:ix1] = 1\n",
    "\n",
    "fig,axs = plt.subplots(1,2)\n",
    "axs[0].plot(x,y,'k')\n",
    "axs[0].set_xlabel('distance (m)')\n",
    "axs[0].set_ylabel('value')\n",
    "axs[1].plot(np.arange(len(x)), y,'k')\n",
    "axs[1].set_xlabel('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a signal to correlate with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c750d02482a4ad08d1734b804f57b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'black = original, blue = shifted')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imposed_offset = int(14/dx) # 14 meters, in units of samples\n",
    "\n",
    "x_noise = np.arange(0,50,dx) # make the vector we're comparing with much longer\n",
    "y_noise = np.zeros(np.shape(x_noise))\n",
    "y_noise[ix0 + imposed_offset : ix1 + imposed_offset] = 1\n",
    "\n",
    "# uncomment the line below to add noise\n",
    "# y_noise = y_noise * np.random.random(np.shape(y_noise))\n",
    "\n",
    "fig,axs = plt.subplots(1,2)\n",
    "\n",
    "axs[0].plot(x,y,'k')\n",
    "axs[0].set_xlabel('distance (m)')\n",
    "axs[0].set_ylabel('value')\n",
    "axs[1].plot(np.arange(len(x)), y, 'k')\n",
    "axs[1].set_xlabel('index')\n",
    "\n",
    "axs[0].plot(x_noise,y_noise, 'b')\n",
    "axs[0].set_xlabel('distance (m)')\n",
    "axs[0].set_ylabel('value')\n",
    "axs[1].plot(np.arange(len(x_noise)), y_noise,'b')\n",
    "axs[1].set_xlabel('index')\n",
    "\n",
    "fig.suptitle('black = original, blue = shifted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try scipy.signal.correlate:\n",
    "\n",
    "mode ='full' returns the entire cross correlation; could be 'valid' to return only non- zero-padded part\n",
    "\n",
    "method = direct (not fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = correlate(y_noise,y, mode = 'full', method = 'direct') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the dimensions of corr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr:  (599,)\n",
      "x:  (100,)\n"
     ]
    }
   ],
   "source": [
    "print('corr: ', np.shape(corr))\n",
    "print('x: ', np.shape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a9e4b463fc4e62b89d71a0a1cee69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Shift  140  samples, or  14.0  m to line up signals')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lagvec = np.arange(0,len(x_noise) - len(x) + 1)\n",
    "lagvec = np.arange( -(len(x) - 1), len(x_noise), 1)\n",
    "shift_vec = lagvec * dx\n",
    "\n",
    "ix_peak = np.arange(len(corr))[corr == np.nanmax(corr)][0]\n",
    "best_lag = lagvec[ix_peak]\n",
    "best_shift = shift_vec[ix_peak]\n",
    "\n",
    "fig,axs = plt.subplots(3,1)\n",
    "\n",
    "axs[0].plot(lagvec,corr)\n",
    "axs[0].plot(lagvec[ix_peak],corr[ix_peak], 'r*')\n",
    "axs[0].set_xlabel('lag (samples)')\n",
    "axs[0].set_ylabel('correlation coefficient')\n",
    "\n",
    "axs[1].plot(shift_vec,corr)\n",
    "axs[1].plot(shift_vec[ix_peak],corr[ix_peak], 'r*')\n",
    "axs[1].set_xlabel('shift (m)')\n",
    "axs[1].set_ylabel('correlation coefficient')\n",
    "\n",
    "axs[2].plot(x + best_shift, y,'k')\n",
    "axs[2].plot(x_noise, y_noise, 'b--')\n",
    "axs[2].set_xlabel('shift (m)')\n",
    "\n",
    "\n",
    "fig.suptitle(' '.join(['Shift ', str(best_lag), ' samples, or ', str(best_shift), ' m to line up signals']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try with some ATL06 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some repeat data:\n",
    "\n",
    "\n",
    "import readers, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ..; [ -d pointCollection ] || git clone https://www.github.com/smithB/pointCollection.git\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "import pointCollection as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_datapath = '/srv/tutorial-data/land_ice_applications/'\n",
    "datapath = '/home/jovyan/shared/surface_velocity/FIS_ATL06/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geographic setting : Foundation Ice Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something wrong with pointCollection\n",
    "\n",
    "# spatial_extent = np.array([-102, -76, -98, -74.5])\n",
    "# lat=spatial_extent[[1, 3, 3, 1, 1]]\n",
    "# lon=spatial_extent[[2, 2, 0, 0, 2]]\n",
    "# print(lat)\n",
    "# print(lon)\n",
    "# # project the coordinates to Antarctic polar stereographic\n",
    "# xy=np.array(pyproj.Proj(3031)(lon, lat))\n",
    "# # get the bounds of the projected coordinates \n",
    "# XR=[np.nanmin(xy[0,:]), np.nanmax(xy[0,:])]\n",
    "# YR=[np.nanmin(xy[1,:]), np.nanmax(xy[1,:])]\n",
    "# MOA=pc.grid.data().from_geotif(os.path.join(data_root, 'MOA','moa_2009_1km.tif'), bounds=[XR, YR])\n",
    "\n",
    "# # show the mosaic:\n",
    "# plt.figure()\n",
    "# MOA.show(cmap='gray', clim=[14000, 17000])\n",
    "# plt.plot(xy[0,:], xy[1,:])\n",
    "# plt.title('Mosaic of Antarctica for Pine Island Glacier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load repeat track data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATL06 reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atl06_to_dict(filename, beam, field_dict=None, index=None, epsg=None):\n",
    "    \"\"\"\n",
    "        Read selected datasets from an ATL06 file\n",
    "\n",
    "        Input arguments:\n",
    "            filename: ATl06 file to read\n",
    "            beam: a string specifying which beam is to be read (ex: gt1l, gt1r, gt2l, etc)\n",
    "            field_dict: A dictinary describing the fields to be read\n",
    "                    keys give the group names to be read, \n",
    "                    entries are lists of datasets within the groups\n",
    "            index: which entries in each field to read\n",
    "            epsg: an EPSG code specifying a projection (see www.epsg.org).  Good choices are:\n",
    "                for Greenland, 3413 (polar stereographic projection, with Greenland along the Y axis)\n",
    "                for Antarctica, 3031 (polar stereographic projection, centered on the Pouth Pole)\n",
    "        Output argument:\n",
    "            D6: dictionary containing ATL06 data.  Each dataset in \n",
    "                dataset_dict has its own entry in D6.  Each dataset \n",
    "                in D6 contains a numpy array containing the \n",
    "                data\n",
    "    \"\"\"\n",
    "    if field_dict is None:\n",
    "        field_dict={None:['latitude','longitude','h_li', 'atl06_quality_summary'],\\\n",
    "                    'ground_track':['x_atc','y_atc'],\\\n",
    "                    'fit_statistics':['dh_fit_dx', 'dh_fit_dy']}\n",
    "    D={}\n",
    "    # below: file_re = regular expression, it will pull apart the regular expression to get the information from the filename\n",
    "    file_re=re.compile('ATL06_(?P<date>\\d+)_(?P<rgt>\\d\\d\\d\\d)(?P<cycle>\\d\\d)(?P<region>\\d\\d)_(?P<release>\\d\\d\\d)_(?P<version>\\d\\d).h5')\n",
    "    with h5py.File(filename,'r') as h5f:\n",
    "        for key in field_dict:\n",
    "            for ds in field_dict[key]:\n",
    "                if key is not None:\n",
    "                    ds_name=beam+'/land_ice_segments/'+key+'/'+ds\n",
    "                else:\n",
    "                    ds_name=beam+'/land_ice_segments/'+ds\n",
    "                if index is not None:\n",
    "                    D[ds]=np.array(h5f[ds_name][index])\n",
    "                else:\n",
    "                    D[ds]=np.array(h5f[ds_name])\n",
    "                if '_FillValue' in h5f[ds_name].attrs:\n",
    "                    bad_vals=D[ds]==h5f[ds_name].attrs['_FillValue']\n",
    "                    D[ds]=D[ds].astype(float)\n",
    "                    D[ds][bad_vals]=np.NaN\n",
    "        D['data_start_utc'] = h5f['/ancillary_data/data_start_utc'][:]\n",
    "        D['delta_time'] = h5f['/gt2l/land_ice_segments/delta_time'][:]\n",
    "    if epsg is not None:\n",
    "        xy=np.array(pyproj.proj.Proj(epsg)(D['longitude'], D['latitude']))\n",
    "        D['x']=xy[0,:].reshape(D['latitude'].shape)\n",
    "        D['y']=xy[1,:].reshape(D['latitude'].shape)\n",
    "    temp=file_re.search(filename)\n",
    "    D['rgt']=int(temp['rgt'])\n",
    "    D['cycle']=int(temp['cycle'])\n",
    "    D['beam']=beam\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in files; this next cell took ~1 minute early in the morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190430122344_04920311_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20181030210407_04920111_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190730080323_04920411_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190220230230_08320211_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190312235510_11380211_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20181108184743_06280111_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190228224553_09540211_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190623094402_13150311_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190506112405_05830311_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190611193446_11380311_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190620171809_12740311_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190823150456_08630411_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190529105941_09340311_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190308130329_10700211_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190824143917_08780411_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190812071246_06900411_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20181118033101_07710111_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190822060451_08420411_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190607194306_10770311_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "file /home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190129164404_04920211_003_01.h5 encountered error 'Unable to open object (component not found)'\n",
      "read 613 data files of which 20 gave errors\n"
     ]
    }
   ],
   "source": [
    "# find all the files in the directory:\n",
    "# ATL06_files=glob.glob(os.path.join(datapath, 'PIG_ATL06', '*.h5'))\n",
    "\n",
    "ATL06_files=glob.glob(os.path.join(datapath, '*.h5'))\n",
    "\n",
    "D_dict={}\n",
    "error_count=0\n",
    "for file in ATL06_files:\n",
    "    try:\n",
    "        D_dict[file]=atl06_to_dict(file, '/gt2l', index=slice(0, -1, 25), epsg=3031)\n",
    "    except KeyError as e:\n",
    "        print(f'file {file} encountered error {e}')\n",
    "        error_count += 1\n",
    "print(f\"read {len(D_dict)} data files of which {error_count} gave errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ground tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b012b4b3dd94333b52af8ad5539de1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "hax0=plt.gcf().add_subplot(211, aspect='equal')\n",
    "# MOA.show(ax=hax0, cmap='gray', clim=[14000, 17000]);\n",
    "hax1=plt.gcf().add_subplot(212, aspect='equal', sharex=hax0, sharey=hax0)\n",
    "# MOA.show(ax=hax1, cmap='gray', clim=[14000, 17000]);\n",
    "for fname, Di in D_dict.items():\n",
    "    cycle=Di['cycle']\n",
    "    if cycle <= 2:\n",
    "        ax=hax0\n",
    "    else:\n",
    "        ax=hax1\n",
    "    #print(fname)\n",
    "    #print(f'\\t{rgt}, {cycle}, {region}')\n",
    "    ax.plot(Di['x'], Di['y'])\n",
    "    if True:\n",
    "        try:\n",
    "            if cycle  < 3:\n",
    "                ax.text(Di['x'][0], Di['y'][0], f\"rgt={Di['rgt']}, cyc={cycle}\", clip_on=True)\n",
    "            elif cycle==3:\n",
    "                ax.text(Di['x'][0], Di['y'][0], f\"rgt={Di['rgt']}, cyc={cycle}+\", clip_on=True)\n",
    "        except IndexError:\n",
    "            pass\n",
    "hax0.set_title('cycles 1 and 2');\n",
    "hax1.set_title('cycle 3+');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map view elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6b39301d2740beb17ed43be74e7870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_fig=plt.figure()\n",
    "map_ax=map_fig.add_subplot(111)\n",
    "# MOA.show(ax=map_ax, cmap='gray', clim=[14000, 17000])\n",
    "for fname, Di in D_dict.items():\n",
    "    # select elevations with good quality_summary\n",
    "    good=Di['atl06_quality_summary']==0\n",
    "    ms=map_ax.scatter( Di['x'][good], Di['y'][good],  2, c=Di['h_li'][good], \\\n",
    "                  vmin=0, vmax=1000, label=fname)\n",
    "map_ax._aspect='equal'\n",
    "plt.colorbar(ms, label='elevation');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat track elevation profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ben Smiths's code to plot the individual segments:\n",
    "def plot_segs(D6, ind=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot a sloping line for each ATL06 segment\n",
    "    \"\"\"\n",
    "    if ind is None:\n",
    "        ind=np.ones_like(D6['h_li'], dtype=bool)\n",
    "    #define the heights of the segment endpoints.  Leave a row of NaNs so that the endpoints don't get joined\n",
    "    h_ep=np.zeros([3, D6['h_li'][ind].size])+np.NaN\n",
    "    h_ep[0, :]=D6['h_li'][ind]-D6['dh_fit_dx'][ind]*20\n",
    "    h_ep[1, :]=D6['h_li'][ind]+D6['dh_fit_dx'][ind]*20\n",
    "    # define the x coordinates of the segment endpoints\n",
    "    x_ep=np.zeros([3,D6['h_li'][ind].size])+np.NaN\n",
    "    x_ep[0, :]=D6['x_atc'][ind]-20\n",
    "    x_ep[1, :]=D6['x_atc'][ind]+20\n",
    "\n",
    "    plt.plot(x_ep.T.ravel(), h_ep.T.ravel(), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A revised code to plot the elevations of segment midpoints (h_li):\n",
    "def plot_elevation(D6, ind=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot midpoint elevation for each ATL06 segment\n",
    "    \"\"\"\n",
    "    if ind is None:\n",
    "        ind=np.ones_like(D6['h_li'], dtype=bool)\n",
    "    # pull out heights of segment midpoints\n",
    "    h_li = D6['h_li'][ind]\n",
    "    # pull out along track x coordinates of segment midpoints\n",
    "    x_atc = D6['x_atc'][ind]\n",
    "\n",
    "    plt.plot(x_atc, h_li, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3084367e60514075926e7c71496dab7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_2l={}\n",
    "D_2r={}\n",
    "\n",
    "# specify the rgt here:\n",
    "rgt=\"0027\"\n",
    "rgt=\"0848\" #Ben's suggestion\n",
    "\n",
    "# iterate over the repeat cycles\n",
    "for cycle in ['03','04','05','06','07']:\n",
    "    for filename in glob.glob(os.path.join(datapath, f'*ATL06_*_{rgt}{cycle}*_003*.h5')):\n",
    "        try:\n",
    "            # read the left-beam data\n",
    "            D_2l[filename]=atl06_to_dict(filename,'/gt2l', index=None, epsg=3031)\n",
    "            # read the right-beam data\n",
    "            D_2r[filename]=atl06_to_dict(filename,'/gt2r', index=None, epsg=3031)\n",
    "            # plot the locations in the previous plot\n",
    "            map_ax.plot(D_2r[filename]['x'], D_2r[filename]['y'],'k');  \n",
    "            map_ax.plot(D_2l[filename]['x'], D_2l[filename]['y'],'k');\n",
    "        except Exception as e:\n",
    "            print(f'filename={filename}, exception={e}')\n",
    "\n",
    "plt.figure();\n",
    "for filename, Di in D_2l.items():\n",
    "    #Plot only points that have ATL06_quality_summary==0 (good points)\n",
    "    hl=plot_elevation(Di, ind=Di['atl06_quality_summary']==0, label=f\"cycle={Di['cycle']}\")\n",
    "    #hl=plt.plot(Di['x_atc'][Di['atl06_quality_summary']==0], Di['h_li'][Di['atl06_quality_summary']==0], '.', label=f\"cycle={Di['cycle']}\")\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('x_atc')\n",
    "plt.ylabel('elevation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190523195046_08480311_003_01.h5': {'latitude': array([-81.00013194, -81.00030512, -81.00047831, ..., -84.67946024,\n",
       "         -84.67962458, -84.67979097]),\n",
       "  'longitude': array([-55.5005578 , -55.50082636, -55.50109458, ..., -64.99792596,\n",
       "         -64.99865297, -64.99937885]),\n",
       "  'h_li': array([ 99.54535675,  99.54103851,  99.53070831, ..., 859.45227051,\n",
       "         861.23077393, 863.00732422]),\n",
       "  'atl06_quality_summary': array([0, 0, 0, ..., 0, 0, 0], dtype=int8),\n",
       "  'x_atc': array([29124294.45759735, 29124314.35642577, 29124334.25525408, ...,\n",
       "         29554562.35604185, 29554582.25280255, 29554602.14956318]),\n",
       "  'y_atc': array([36.54935455, 36.47702026, 36.40297699, ..., 41.22812271,\n",
       "         41.26498795, 41.31079865]),\n",
       "  'dh_fit_dx': array([ 0.00069716, -0.00437041,  0.00213977, ...,  0.09347188,\n",
       "          0.08618674,  0.08833945]),\n",
       "  'dh_fit_dy': array([-0.00027616, -0.00047952, -0.00055422, ..., -0.00706493,\n",
       "         -0.00545145, -0.00413069]),\n",
       "  'data_start_utc': array([b'2019-05-23T19:50:46.495345Z'], dtype='|S27'),\n",
       "  'delta_time': array([43876278.88573127, 43876278.88854948, 43876278.89136732, ...,\n",
       "         43876339.84119466, 43876339.84401926, 43876339.84683304]),\n",
       "  'x': array([-807477.57177053, -807464.57386477, -807451.57141323, ...,\n",
       "         -524279.88417308, -524266.77025482, -524253.44916997]),\n",
       "  'y': array([554952.38518484, 554937.87980219, 554923.37842858, ...,\n",
       "         244498.83045416, 244484.61570217, 244470.31750585]),\n",
       "  'rgt': 848,\n",
       "  'cycle': 3,\n",
       "  'beam': '/gt2l'},\n",
       " '/home/jovyan/shared/surface_velocity/FIS_ATL06/processed_ATL06_20190822153035_08480411_003_01.h5': {'latitude': array([-81.00014668, -81.00032005, -81.00049342, ..., -84.67949732,\n",
       "         -84.67956045, -84.67972019]),\n",
       "  'longitude': array([-55.50016429, -55.50042748, -55.50069086, ..., -64.99782155,\n",
       "         -64.99855105, -64.99928113]),\n",
       "  'h_li': array([ 99.81712341,  99.84939575,  99.87688446, ..., 859.76263428,\n",
       "         861.56896973, 863.22290039]),\n",
       "  'atl06_quality_summary': array([0, 0, 0, ..., 0, 0, 0], dtype=int8),\n",
       "  'x_atc': array([29124294.45759735, 29124314.35642577, 29124334.25525408, ...,\n",
       "         29554562.35604185, 29554582.25280255, 29554602.14956318]),\n",
       "  'y_atc': array([43.62549973, 43.64395523, 43.66313553, ..., 42.40289307,\n",
       "         42.40867233, 42.41308975]),\n",
       "  'dh_fit_dx': array([ 0.00507986, -0.0015735 ,  0.005316  , ...,  0.09680843,\n",
       "          0.08671474,  0.07646322]),\n",
       "  'dh_fit_dy': array([-0.00039021,  0.0003108 , -0.00020378, ...,         nan,\n",
       "                 nan, -0.00889655]),\n",
       "  'data_start_utc': array([b'2019-08-22T15:30:35.069787Z'], dtype='|S27'),\n",
       "  'delta_time': array([51723067.45898565, 51723067.46181254, 51723067.46463379, ...,\n",
       "         51723128.41457503, 51723128.41741031, 51723128.42024656]),\n",
       "  'x': array([-807472.4331371 , -807459.36521844, -807446.29984956, ...,\n",
       "         -524275.78045706, -524272.66341908, -524260.01676487]),\n",
       "  'y': array([554957.01883345, 554942.57658511, 554928.13222699, ...,\n",
       "         244498.07976865, 244488.49938475, 244474.46869545]),\n",
       "  'rgt': 848,\n",
       "  'cycle': 4,\n",
       "  'beam': '/gt2l'}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull out a segment and cross correlate: \n",
    "\n",
    "Let's try x_atc = 2.935e7 thru 2.93e7 (just from looking through data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b53d610054b40bbb854a81f06aa34cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cycles = [] # names of cycles with data\n",
    "for filename, Di in D_2l.items():\n",
    "    cycles += [str(Di['cycle']).zfill(2)]\n",
    "cycles.sort()\n",
    "    \n",
    "# x1 = 2.93e7\n",
    "# x2 = 2.935e7\n",
    "\n",
    "beams = ['gt1l','gt1r','gt2l','gt2r','gt3l','gt3r']\n",
    "\n",
    "### extract and plot data from all available cycles\n",
    "fig, axs = plt.subplots(3,1)\n",
    "x_atc = {}\n",
    "h_li = {}\n",
    "h_li_diff = {}\n",
    "times = {}\n",
    "for cycle in cycles:\n",
    "    # find Di that matches cycle:\n",
    "    Di = {}\n",
    "    x_atc[cycle] = {}\n",
    "    h_li[cycle] = {}\n",
    "    h_li_diff[cycle] = {}\n",
    "    times[cycle] = {}\n",
    "\n",
    "    filenames = glob.glob(os.path.join(datapath, f'*ATL06_*_{rgt}{cycle}*_003*.h5'))\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            for beam in beams:\n",
    "                # read the left-beam data\n",
    "                Di[filename]=atl06_to_dict(filename,'/'+ beam, index=None, epsg=3031)\n",
    "#                 # read the right-beam data\n",
    "#                 Di[filename]=atl06_to_dict(filename,'/gt2r', index=None, epsg=3031)\n",
    "\n",
    "                # pull out info for this cycle\n",
    "#                 x_tmp = Di[filename]['x_atc']\n",
    "#                 ixs = (x_tmp >=x1) * (x_tmp <= x2)\n",
    "                times[cycle][beam] = Di[filename]['data_start_utc']\n",
    "\n",
    "                # extract h_li and x_atc for that section\n",
    "                x_atc[cycle][beam] = Di[filename]['x_atc']#[ixs]\n",
    "                h_li[cycle][beam] = Di[filename]['h_li']#[ixs]\n",
    "\n",
    "#                 # here is where you would put a filter\n",
    "#                 # you would want to de-mean and detrend that section first:\n",
    "#                 h = Di[filename]['h_li']#[ixs]\n",
    "#                 x = Di[filename]['x_atc']#[ixs]\n",
    "#                 h = h - np.nanmean(h) # de-mean\n",
    "#                 h = scipy.signal.detrend(h, type = 'linear') # de-trend; need to deal with nans first\n",
    "#                 # use scipy.signal.filter to filter\n",
    "\n",
    "#                 # differentiate that section of data\n",
    "                h = Di[filename]['h_li']#[ixs]\n",
    "                x = Di[filename]['x_atc']#[ixs]\n",
    "                h_diff = (h[1:] - h[0:-1]) / (x[1:] - x[0:-1])\n",
    "                h_li_diff[cycle][beam] = h_diff\n",
    "\n",
    "                # plot\n",
    "                axs[0].plot(x_atc[cycle][beam], h_li[cycle][beam])\n",
    "                axs[1].plot(x_atc[cycle][beam][1:], h_diff)\n",
    "        except:\n",
    "            print(f'filename={filename}, exception={e}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'03': {'gt1l': array([ 100.42033386,  100.50815582,  100.46810913, ..., 1147.96044922,\n",
       "         1146.5111084 , 1145.22692871]),\n",
       "  'gt1r': array([ 100.39672089,  100.42650604,  100.47757721, ..., 1151.83862305,\n",
       "         1151.52124023, 1151.27600098]),\n",
       "  'gt2l': array([ 99.54535675,  99.54103851,  99.53070831, ..., 859.45227051,\n",
       "         861.23077393, 863.00732422]),\n",
       "  'gt2r': array([ 99.58573151,  99.58233643,  99.58412933, ..., 853.95965576,\n",
       "         853.60754395, 853.29498291]),\n",
       "  'gt3l': array([ 99.32234955,  99.31598663,  99.34339142, ..., 766.20257568,\n",
       "         766.42669678, 766.5579834 ]),\n",
       "  'gt3r': array([ 99.3686142 ,  99.49465179,  99.55793762, ..., 763.80133057,\n",
       "         763.98974609, 764.18457031])},\n",
       " '04': {'gt1l': array([ 100.63162994,  100.56430817,  100.57009125, ..., 1147.72546387,\n",
       "         1146.29492188, 1145.07641602]),\n",
       "  'gt1r': array([100.78127289, 100.78099823, 100.77690887, ...,          nan,\n",
       "                  nan,          nan]),\n",
       "  'gt2l': array([ 99.81712341,  99.84939575,  99.87688446, ..., 859.76263428,\n",
       "         861.56896973, 863.22290039]),\n",
       "  'gt2r': array([99.82043457, 99.89587402, 99.87844849, ...,         nan,\n",
       "                 nan,         nan]),\n",
       "  'gt3l': array([ 99.55401611,  99.50902557,  99.51152039, ..., 766.31359863,\n",
       "         766.57165527, 766.69244385]),\n",
       "  'gt3r': array([99.61916351, 99.58298492, 99.58996582, ...,         nan,\n",
       "                 nan,         nan])}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04\n"
     ]
    }
   ],
   "source": [
    "# Average together all cycles for each beam\n",
    "h_li_avg = {}\n",
    "for beam in beams:\n",
    "\n",
    "    # loop through all cycles to calculate average h_li for each beam\n",
    "    h_li_cycles_sum=h_li[cycles[0]][beam]\n",
    "\n",
    "    for cycle in cycles[1:]:\n",
    "        print(cycle)\n",
    "        h_li_cycles_sum += h_li[cycle][beam]\n",
    "\n",
    "    h_li_avg[beam] = h_li_cycles_sum / len(cycles)        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(len(cycles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542fdca84c83498b92f37cbcff867178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (202,) and (203,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-d5db5365f6ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlagvec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlagvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix_peak\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix_peak\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lag (samples)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (202,) and (203,)"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "n_veloc = len(cycles) - 1\n",
    "\n",
    "x1 = 2.93e7\n",
    "x2 = 2.931e7\n",
    "\n",
    "search_width = 2000 # m\n",
    "dx = 20 # meters between x_atc points\n",
    "\n",
    "for veloc_number in range(n_veloc):\n",
    "    cycle1 = cycles[veloc_number]\n",
    "    cycle2 = cycles[veloc_number+1]\n",
    "    t1_string = times[cycle1]['gt1l'][0].astype(str) #figure out later if just picking hte first one it ok\n",
    "    t1 = Time(t1_string)\n",
    "                       \n",
    "    t2_string = times[cycle2]['gt1l'][0].astype(str) #figure out later if just picking hte first one it ok\n",
    "    t2 = Time(t2_string)\n",
    "    \n",
    "    dt = (t2 - t1).jd # difference in julian days\n",
    "        \n",
    "                   \n",
    "    for beam in beams:\n",
    "        fig1, axs = plt.subplots(3,1)\n",
    "        \n",
    "        # cut out small chunk of data at time t1 (first cycle)\n",
    "        x_full_t1 = x_atc[cycle1][beam]\n",
    "        ixs = (x_full_t1 >=x1) * (x_full_t1 <= x2)\n",
    "        x_t1 = x_full_t1[ixs]\n",
    "        h_li1 = h_li_diff[cycle1][beam][ixs[1:]] # start at index 1 because the data are differentiated\n",
    "        \n",
    "        # cut out a wider chunk of data at time t2 (second cycle)\n",
    "        x_full_t2 = x_atc[cycle2][beam]\n",
    "        ixs = (x_full_t2 >=(x1 - search_width)) * (x_full_t2 <= (x2 + search_width))\n",
    "        x_t2 = x_full_t2[ixs]\n",
    "        h_li2 = h_li_diff[cycle2][beam][ixs[1:]]\n",
    "\n",
    "        # plot data\n",
    "        axs[0].plot(x_t2, h_li2, 'r')\n",
    "        axs[0].plot(x_t1, h_li1, 'k')\n",
    "        axs[0].set_xlabel('x_atc (m)')\n",
    "        \n",
    "        # correlate old with newer data\n",
    "        corr = correlate(h_li1, h_li2, mode = 'valid', method = 'direct') \n",
    "\n",
    "#         lagvec = np.arange( -(len(h_li1) - 1), len(h_li2), 1)# for mode = 'full'\n",
    "        lagvec = np.arange( -round(search_width/dx) - 1, round(search_width/dx) + 1, 1 ) # for mode = 'valid'\n",
    "        shift_vec = lagvec * dx\n",
    "\n",
    "        ix_peak = np.arange(len(corr))[corr == np.nanmax(corr)][0]\n",
    "        best_lag = lagvec[ix_peak]\n",
    "        best_shift = shift_vec[ix_peak]\n",
    "\n",
    "\n",
    "        axs[1].plot(lagvec,corr)\n",
    "        axs[1].plot(lagvec[ix_peak],corr[ix_peak], 'r*')\n",
    "        axs[1].set_xlabel('lag (samples)')\n",
    "\n",
    "        axs[2].plot(shift_vec,corr)\n",
    "        axs[2].plot(shift_vec[ix_peak],corr[ix_peak], 'r*')\n",
    "        axs[2].set_xlabel('shift (m)')\n",
    "\n",
    "        axs[0].text(x_t2[100], 0.6*np.nanmax(h_li2), beam)\n",
    "        axs[1].text(lagvec[5], 0.6*np.nanmax(corr), 'best lag: ' + str(best_lag) + '; corr val: ' + str(np.round(corr[ix_peak],3)))\n",
    "        axs[2].text(shift_vec[5], 0.6*np.nanmax(corr), 'best shift: ' + str(best_shift) + ' m'+ '; corr val: ' + str(np.round(corr[ix_peak],3)))\n",
    "        axs[2].text(shift_vec[5], 0.3*np.nanmax(corr), 'veloc of ' + str(np.round(best_shift/(dt/365),1)) + ' m/yr')\n",
    "\n",
    "        \n",
    "    fig1.suptitle('black = older cycle data, red = newer cycle data to search across')\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
