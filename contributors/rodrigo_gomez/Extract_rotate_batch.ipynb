{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re,h5py\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import scipy, sys, os, pyproj, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, Polygon\n",
    "import pointCollection as pc\n",
    "import math\n",
    "\n",
    "# Import some of the scripts that we have written\n",
    "import sys\n",
    "#sys.path.append(\"/home/jovyan/surface_velocity/scripts\")\n",
    "sys.path.append(\"/home/UOCNT/rag110/Dropbox/UC_files/Data_Wrangling/ICESat2Hackweek2020/surface_velocity/scripts\")\n",
    "from loading_scripts import atl06_to_dict\n",
    "\n",
    "\n",
    "# run matplotlib in 'widget' mode\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-86 -81 -81 -86 -86]\n",
      "[-55 -55 -65 -65 -55]\n"
     ]
    }
   ],
   "source": [
    "#From Ben Smith's code loading in .tif file, running into issues likely with directories\n",
    "#data_root='/srv/shared/surface_velocity/FIS_Velocity/'\n",
    "#spatial_extent = np.array([-102, -76, -98, -74.5])\n",
    "spatial_extent = np.array([-65, -86, -55, -81])\n",
    "lat=spatial_extent[[1, 3, 3, 1, 1]]\n",
    "lon=spatial_extent[[2, 2, 0, 0, 2]]\n",
    "print(lat)\n",
    "print(lon)\n",
    "# project the coordinates to Antarctic polar stereographic\n",
    "xy=np.array(pyproj.Proj(3031)(lon, lat))\n",
    "# get the bounds of the projected coordinates \n",
    "XR=[np.nanmin(xy[0,:]), np.nanmax(xy[0,:])]\n",
    "YR=[np.nanmin(xy[1,:]), np.nanmax(xy[1,:])]\n",
    "#Originally tried to load data from a local directory, should change to shared directory\n",
    "#Measures_vx=pc.grid.data().from_geotif(os.path.join(data_root,'Measures2_FIS_Vx.tif'), bounds=[XR, YR])\n",
    "#Measures_vy=pc.grid.data().from_geotif(os.path.join(data_root,'Measures2_FIS_Vy.tif'), bounds=[XR, YR])\n",
    "\n",
    "#Rodrigo Gomez Fell computer path @ UC\n",
    "data_root = '/mnt/user1/Antarctica/Quantarctica3/Glaciology/MEaSUREs Ice Flow Velocity/'\n",
    "\n",
    "Measures_vx=pc.grid.data().from_geotif(os.path.join(data_root,'anta_phase_map_VX.tif'), bounds=[XR, YR])\n",
    "Measures_vy=pc.grid.data().from_geotif(os.path.join(data_root,'anta_phase_map_VY.tif'), bounds=[XR, YR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pointCollection as pc\n",
    "\n",
    "def add_surface_velocity_to_is2_dict(is2_dict, spatial_extent, path, vel_x, vel_y ):\n",
    "    \"\"\"\n",
    "    \n",
    "    is2_dict: Python dictionary with ATL06 track data\n",
    "    spatial_extent: bounding box of the interest area in the format:\n",
    "                    (e.g. [-65, -86, -55, -81] == [min_lon, min_lat, max_lon, max_lat])\n",
    "    path: local path to velocity data\n",
    "    vel_x: tif velocity raster with x component\n",
    "    vel_y: tif velocity raster with y component\n",
    "    \n",
    "    \"\"\"\n",
    "    data_root = path\n",
    "    \n",
    "    spatial_extent = np.array([spatial_extent])\n",
    "    lat=spatial_extent[[1, 3, 3, 1, 1]]\n",
    "    lon=spatial_extent[[2, 2, 0, 0, 2]]\n",
    "    print(lat)\n",
    "    print(lon)\n",
    "    # project the coordinates to Antarctic polar stereographic\n",
    "    xy=np.array(pyproj.Proj(3031)(lon, lat))\n",
    "    # get the bounds of the projected coordinates \n",
    "    XR=[np.nanmin(xy[0,:]), np.nanmax(xy[0,:])]\n",
    "    YR=[np.nanmin(xy[1,:]), np.nanmax(xy[1,:])]\n",
    "    \n",
    "    Measures_vx=pc.grid.data().from_geotif(os.path.join(data_root,vel_x), bounds=[XR, YR])\n",
    "    Measures_vy=pc.grid.data().from_geotif(os.path.join(data_root,vel_y), bounds=[XR, YR])\n",
    "    \n",
    "    vx = Measures_vx.interp(is2_dict['x'],is2_dict['y'])\n",
    "    vy = Measures_vy.interp(is2_dict['x'],is2_dict['y'])\n",
    "\n",
    "    #Solve for angle to rotate Vy to be along track and Vx to be across track\n",
    "    import math\n",
    "    xL=abs((is2_dict['x'][0])-(is2_dict['x'][1]))\n",
    "    yL=abs((is2_dict['y'][0])-(is2_dict['y'][1]))\n",
    "\n",
    "    #decides if is descending or ascending path\n",
    "    if is2_dict['x'][0]-is2_dict['x'][1] < 0:\n",
    "\n",
    "        theta_rad=math.atan(xL/yL)\n",
    "        #theta_deg=theta_rad*180/math.pi\n",
    "        is2_dict['v_along']=vy/math.cos(theta_rad)\n",
    "        is2_dict['v_across']=vx/math.cos(theta_rad)\n",
    "\n",
    "    else:\n",
    "    \n",
    "        theta_rad=math.atan(xL/yL)\n",
    "        #theta_deg=theta_rad*180/math.pi\n",
    "        is2_dict['v_along']=vy/math.sin(theta_rad)\n",
    "        is2_dict['v_across']=vx/math.sin(theta_rad)\n",
    "        \n",
    "    return is2_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ATL06='/media/rag110/ADATA SD700/ICESat2/download/'\n",
    "field_dict={None:['delta_time','latitude','longitude','h_li', 'atl06_quality_summary'],\\\n",
    "                    'ground_track':['x_atc','y_atc'],\\\n",
    "                    'fit_statistics':['dh_fit_dx', 'dh_fit_dy']}\n",
    "\n",
    "ATL06_files = glob.glob(os.path.join(data_ATL06, 'FIS', f'*ATL06_*_*_003*.h5'))\n",
    "\n",
    "rgts = {}\n",
    "for filepath in ATL06_files:\n",
    "    filename = filepath.split('/')[-1]\n",
    "    rgt = filename.split('_')[3][0:4]\n",
    "    track = filename.split('_')[3][4:6]\n",
    "#     print(rgt,track)\n",
    "    if not rgt in rgts.keys():\n",
    "        rgts[rgt] = []\n",
    "        rgts[rgt].append(track)\n",
    "    else:\n",
    "        rgts[rgt].append(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Revised version of code from Ben Smith to read in the hdf5 files and extract necessary datasets and information\n",
    "def atl06_to_dict(filename, beam, field_dict=None, index=None, epsg=None):\n",
    "    \"\"\"\n",
    "        Read selected datasets from an ATL06 file\n",
    "\n",
    "        Input arguments:\n",
    "            filename: ATl06 file to read\n",
    "            beam: a string specifying which beam is to be read (ex: gt1l, gt1r, gt2l, etc)\n",
    "            field_dict: A dictinary describing the fields to be read\n",
    "                    keys give the group names to be read, \n",
    "                    entries are lists of datasets within the groups\n",
    "            index: which entries in each field to read\n",
    "            epsg: an EPSG code specifying a projection (see www.epsg.org).  Good choices are:\n",
    "                for Greenland, 3413 (polar stereographic projection, with Greenland along the Y axis)\n",
    "                for Antarctica, 3031 (polar stereographic projection, centered on the Pouth Pole)\n",
    "        Output argument:\n",
    "            D6: dictionary containing ATL06 data.  Each dataset in \n",
    "                dataset_dict has its own entry in D6.  Each dataset \n",
    "                in D6 contains a numpy array containing the \n",
    "                data\n",
    "    \"\"\"\n",
    "    if field_dict is None:\n",
    "        field_dict={None:['latitude','longitude','h_li', 'atl06_quality_summary'],\\\n",
    "                    'ground_track':['x_atc','y_atc'],\\\n",
    "                    'fit_statistics':['dh_fit_dx', 'dh_fit_dy']}\n",
    "    D={}\n",
    "    # below: file_re = regular expression, it will pull apart the regular expression to get the information from the filename\n",
    "    file_re=re.compile('ATL06_(?P<date>\\d+)_(?P<rgt>\\d\\d\\d\\d)(?P<cycle>\\d\\d)(?P<region>\\d\\d)_(?P<release>\\d\\d\\d)_(?P<version>\\d\\d).h5')\n",
    "    with h5py.File(filename,'r') as h5f:\n",
    "        for key in field_dict:\n",
    "            for ds in field_dict[key]:\n",
    "                if key is not None:\n",
    "                    ds_name=beam+'/land_ice_segments/'+key+'/'+ds\n",
    "                else:\n",
    "                    ds_name=beam+'/land_ice_segments/'+ds\n",
    "                if index is not None:\n",
    "                    D[ds]=np.array(h5f[ds_name][index])\n",
    "                else:\n",
    "                    D[ds]=np.array(h5f[ds_name])\n",
    "                if '_FillValue' in h5f[ds_name].attrs:\n",
    "                    bad_vals=D[ds]==h5f[ds_name].attrs['_FillValue']\n",
    "                    D[ds]=D[ds].astype(float)\n",
    "                    D[ds][bad_vals]=np.NaN\n",
    "        D['data_start_utc'] = h5f['/ancillary_data/data_start_utc'][:]\n",
    "        D['delta_time'] = h5f['/' + beam + '/land_ice_segments/delta_time'][:]\n",
    "        D['segment_id'] = h5f['/' + beam + '/land_ice_segments/segment_id'][:]\n",
    "    if epsg is not None:\n",
    "        xy=np.array(pyproj.proj.Proj(epsg)(D['longitude'], D['latitude']))\n",
    "        D['x']=xy[0,:].reshape(D['latitude'].shape)\n",
    "        D['y']=xy[1,:].reshape(D['latitude'].shape)\n",
    "    temp=file_re.search(filename)\n",
    "    D['rgt']=int(temp['rgt'])\n",
    "    D['cycle']=int(temp['cycle'])\n",
    "    D['beam']=beam\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "beams = ['/gt1r','/gt1l','/gt2r','/gt2l','/gt3r','/gt3l']\n",
    "D=[]\n",
    "for file in filename:\n",
    "    B = ATL06_to_dict(file, dataset_dict=field_dict)\n",
    "        \n",
    "    add_surface_velocity_to_is2_dict(B)\n",
    "    D.append(B)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:icesat2020] *",
   "language": "python",
   "name": "conda-env-icesat2020-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
